{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Evaluation: Gemini vs Base Qwen\n",
    "\n",
    "This notebook evaluates the baseline performance of:\n",
    "1. **Gemini 2.5 Flash-Lite** (current 2-step pipeline)\n",
    "2. **Qwen3-4B-Instruct-2507** (base model, untuned)\n",
    "\n",
    "Metrics tracked:\n",
    "- Syntactic validity (passes RuleBasedValidator)\n",
    "- Execution success (runs on Neo4j)\n",
    "- Semantic accuracy (exact result match with gold Cypher)\n",
    "- Latency (ms)\n",
    "- Token usage (input/output tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\n",
      "Current working directory: c:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\\finetuning\\notebooks\n",
      "src module verified at: C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\\src\n",
      "Base directory: C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\n",
      "Data directory: C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\\finetuning\\dataset\\splits\n",
      "Evaluation directory: C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\\finetuning\\eval\n",
      "Test subset size: 200\n"
     ]
    }
   ],
   "source": [
    "# Setup & Configuration\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "# In Jupyter notebooks, we need to walk up until we find the project root\n",
    "# The project root should have both pyproject.toml AND src/ directory\n",
    "import os\n",
    "\n",
    "# Manual override: If you know the project root path, uncomment and set it directly\n",
    "# ROOT = Path(r\"C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\").resolve()\n",
    "\n",
    "# Auto-detect by walking up from current directory\n",
    "# Start from current working directory (usually where notebook is located)\n",
    "ROOT = Path(os.getcwd()).resolve()\n",
    "\n",
    "# Walk up until we find a directory with both pyproject.toml AND src/\n",
    "original_cwd = ROOT\n",
    "found_root = False\n",
    "while True:\n",
    "    # Check if this directory looks like the project root\n",
    "    has_pyproject = (ROOT / \"pyproject.toml\").exists()\n",
    "    has_src = (ROOT / \"src\").exists() and (ROOT / \"src\").is_dir()\n",
    "    \n",
    "    if has_pyproject and has_src:\n",
    "        found_root = True\n",
    "        break\n",
    "    \n",
    "    # Go up one level\n",
    "    parent = ROOT.parent\n",
    "    if parent == ROOT:  # Reached filesystem root\n",
    "        break\n",
    "    ROOT = parent\n",
    "\n",
    "if not found_root:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find project root (directory with both pyproject.toml and src/). \"\n",
    "        f\"Current directory: {os.getcwd()}. \"\n",
    "        f\"Please uncomment and set ROOT manually above.\"\n",
    "    )\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(f\"Project root: {ROOT}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"src module verified at: {ROOT / 'src'}\")\n",
    "\n",
    "from src.pipeline.executor import Neo4jExecutor\n",
    "from src.pipeline.gemini import (\n",
    "    GeminiConfig,\n",
    "    GeminiCypherGenerator,\n",
    "    GeminiInstructionExpander,\n",
    ")\n",
    "from src.pipeline.types import PipelineConfig, PipelineError\n",
    "from src.pipeline.validator import RuleBasedValidator\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "TEST_SUBSET_SIZE = 200  # Number of test records to evaluate\n",
    "RATE_LIMIT_RPM = 15  # Gemini rate limit: requests per minute\n",
    "RATE_LIMIT_RPD = 1000  # Gemini rate limit: requests per day\n",
    "\n",
    "# Path configuration (adjust for Colab/local)\n",
    "# For Colab: uncomment and adjust Google Drive paths\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# BASE_DIR = Path(\"/content/drive/MyDrive/OncoGraph-Agent\")\n",
    "\n",
    "# For local: use project root\n",
    "BASE_DIR = ROOT\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"finetuning\" / \"dataset\" / \"splits\"\n",
    "EVAL_DIR = BASE_DIR / \"finetuning\" / \"eval\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Environment variables\n",
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.environ.get(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.environ.get(\"NEO4J_PASSWORD\", \"\")\n",
    "GEMINI_API_KEY = os.environ.get(\"GOOGLE_API_KEY\", \"\")\n",
    "\n",
    "if not NEO4J_PASSWORD:\n",
    "    raise ValueError(\"NEO4J_PASSWORD environment variable not set\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set\")\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Evaluation directory: {EVAL_DIR}\")\n",
    "print(f\"Test subset size: {TEST_SUBSET_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Helper Functions\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def load_test_set(n: int) -> list[dict[str, Any]]:\n",
    "    \"\"\"Load test set and optionally sample n records with stratified sampling.\"\"\"\n",
    "    test_file = DATA_DIR / \"test_sample.jsonl\"\n",
    "    if not test_file.exists():\n",
    "        raise FileNotFoundError(f\"Test file not found: {test_file}\")\n",
    "    \n",
    "    records = []\n",
    "    with test_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            records.append(json.loads(line))\n",
    "    \n",
    "    if n >= len(records):\n",
    "        return records\n",
    "    \n",
    "    # Stratified sampling by template_id\n",
    "    records_by_template = defaultdict(list)\n",
    "    for record in records:\n",
    "        records_by_template[record[\"template_id\"]].append(record)\n",
    "    \n",
    "    sampled = []\n",
    "    for _template_id, template_records in records_by_template.items():\n",
    "        num_to_sample = max(1, int(len(template_records) * (n / len(records))))\n",
    "        if num_to_sample > len(template_records):\n",
    "            num_to_sample = len(template_records)\n",
    "        sampled.extend(template_records[:num_to_sample])\n",
    "    \n",
    "    # If we still need more, randomly sample remaining\n",
    "    if len(sampled) < n:\n",
    "        remaining = [r for r in records if r not in sampled]\n",
    "        import random\n",
    "        random.seed(42)\n",
    "        additional = random.sample(remaining, n - len(sampled))\n",
    "        sampled.extend(additional)\n",
    "    \n",
    "    return sampled[:n]\n",
    "\n",
    "\n",
    "def evaluate_cypher_syntax(\n",
    "    cypher: str, validator: RuleBasedValidator\n",
    ") -> tuple[bool, str | None]:\n",
    "    \"\"\"Check if Cypher passes syntactic validation.\"\"\"\n",
    "    try:\n",
    "        validator.validate_cypher(cypher)\n",
    "        return True, None\n",
    "    except PipelineError as e:\n",
    "        return False, str(e)\n",
    "    except Exception as e:\n",
    "        return False, f\"Unexpected error: {type(e).__name__}: {e}\"\n",
    "\n",
    "\n",
    "def evaluate_cypher_execution(\n",
    "    cypher: str, executor: Neo4jExecutor\n",
    ") -> tuple[bool, list[dict[str, Any]], str | None]:\n",
    "    \"\"\"Execute Cypher and return results.\"\"\"\n",
    "    try:\n",
    "        rows = executor.execute_read(cypher)\n",
    "        return True, rows, None\n",
    "    except Exception as e:\n",
    "        return False, [], f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "\n",
    "def normalize_result_row(row: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Normalize arrays and None values for comparison.\"\"\"\n",
    "    normalized = {}\n",
    "    for key, value in row.items():\n",
    "        if isinstance(value, list):\n",
    "            normalized[key] = sorted(value) if value else []\n",
    "        elif value is None:\n",
    "            normalized[key] = None\n",
    "        else:\n",
    "            normalized[key] = value\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def compare_results(gold_rows: list[dict], generated_rows: list[dict]) -> bool:\n",
    "    \"\"\"Compare result sets for exact match (order-independent).\"\"\"\n",
    "    if len(gold_rows) != len(generated_rows):\n",
    "        return False\n",
    "    \n",
    "    # Normalize and sort rows for comparison\n",
    "    gold_normalized = sorted(\n",
    "        [tuple(sorted(normalize_result_row(row).items())) for row in gold_rows]\n",
    "    )\n",
    "    gen_normalized = sorted(\n",
    "        [tuple(sorted(normalize_result_row(row).items())) for row in generated_rows]\n",
    "    )\n",
    "    \n",
    "    return gold_normalized == gen_normalized\n",
    "\n",
    "\n",
    "def count_tokens(text: str, encoding_name: str = \"o200k_base\") -> int:\n",
    "    \"\"\"Count tokens using tiktoken.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "# Initialize tiktoken encoders\n",
    "GEMINI_ENCODER = tiktoken.get_encoding(\"o200k_base\")  # Compatible with Gemini\n",
    "# For Qwen, we'll use the tokenizer directly since it's available via transformers\n",
    "\n",
    "print(\"Helper functions loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation harness ready\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Harness\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"Evaluation harness for comparing generated Cypher against gold standard.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        validator: RuleBasedValidator,\n",
    "        executor: Neo4jExecutor,\n",
    "        token_encoder: tiktoken.Encoding,\n",
    "    ):\n",
    "        self.validator = validator\n",
    "        self.executor = executor\n",
    "        self.token_encoder = token_encoder\n",
    "    \n",
    "    def evaluate_single(\n",
    "        self,\n",
    "        question: str,\n",
    "        gold_cypher: str,\n",
    "        generated_cypher: str,\n",
    "        prompt_text: str,\n",
    "        model_name: str,\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Evaluate a single generated Cypher query.\"\"\"\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Count tokens\n",
    "        input_tokens = len(self.token_encoder.encode(prompt_text))\n",
    "        output_tokens = len(self.token_encoder.encode(generated_cypher))\n",
    "        \n",
    "        # Syntactic validation\n",
    "        syntactic_valid, syntax_error = evaluate_cypher_syntax(\n",
    "            generated_cypher, self.validator\n",
    "        )\n",
    "        \n",
    "        # Execution (only if syntactically valid)\n",
    "        execution_success = False\n",
    "        execution_error = None\n",
    "        generated_rows = []\n",
    "        if syntactic_valid:\n",
    "            execution_success, generated_rows, execution_error = evaluate_cypher_execution(\n",
    "                generated_cypher, self.executor\n",
    "            )\n",
    "        \n",
    "        # Get gold results (execute once and cache)\n",
    "        _, gold_rows, _ = evaluate_cypher_execution(gold_cypher, self.executor)\n",
    "        \n",
    "        # Result comparison (only if both executed successfully)\n",
    "        result_match = False\n",
    "        if syntactic_valid and execution_success:\n",
    "            result_match = compare_results(gold_rows, generated_rows)\n",
    "        \n",
    "        latency_ms = (time.perf_counter() - start_time) * 1000\n",
    "        \n",
    "        return {\n",
    "            \"syntactic_valid\": syntactic_valid,\n",
    "            \"execution_success\": execution_success,\n",
    "            \"result_match\": result_match,\n",
    "            \"generated_cypher\": generated_cypher,\n",
    "            \"error\": syntax_error or execution_error,\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"gold_rows\": gold_rows,\n",
    "            \"generated_rows\": generated_rows,\n",
    "        }\n",
    "    \n",
    "    def aggregate_metrics(self, results: list[dict[str, Any]]) -> dict[str, Any]:\n",
    "        \"\"\"Aggregate metrics from evaluation results.\"\"\"\n",
    "        total = len(results)\n",
    "        if total == 0:\n",
    "            return {}\n",
    "        \n",
    "        syntactic_valid_count = sum(1 for r in results if r[\"syntactic_valid\"])\n",
    "        execution_success_count = sum(1 for r in results if r[\"execution_success\"])\n",
    "        result_match_count = sum(1 for r in results if r[\"result_match\"])\n",
    "        \n",
    "        total_input_tokens = sum(r[\"input_tokens\"] for r in results)\n",
    "        total_output_tokens = sum(r[\"output_tokens\"] for r in results)\n",
    "        total_latency_ms = sum(r[\"latency_ms\"] for r in results)\n",
    "        \n",
    "        return {\n",
    "            \"total\": total,\n",
    "            \"syntactic_validity_pct\": (syntactic_valid_count / total) * 100,\n",
    "            \"execution_success_pct\": (\n",
    "                (execution_success_count / syntactic_valid_count) * 100\n",
    "                if syntactic_valid_count > 0\n",
    "                else 0.0\n",
    "            ),\n",
    "            \"semantic_accuracy_pct\": (\n",
    "                (result_match_count / execution_success_count) * 100\n",
    "                if execution_success_count > 0\n",
    "                else 0.0\n",
    "            ),\n",
    "            \"avg_latency_ms\": total_latency_ms / total,\n",
    "            \"avg_input_tokens\": total_input_tokens / total,\n",
    "            \"avg_output_tokens\": total_output_tokens / total,\n",
    "            \"total_input_tokens\": total_input_tokens,\n",
    "            \"total_output_tokens\": total_output_tokens,\n",
    "        }\n",
    "\n",
    "print(\"Evaluation harness ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 test records\n",
      "Template distribution:\n",
      "  f1_1_targets_gene: 6\n",
      "  f1_2_genes_for_therapy: 6\n",
      "  f1_3_gene_of_variant: 7\n",
      "  f1_4_variants_of_gene: 7\n",
      "  f2_1_targets_properties: 5\n",
      "  f2_2_gene_affects_therapy_disease: 11\n",
      "  f2_2_gene_affects_therapy_disease_resistance: 12\n",
      "  f2_2_gene_affects_therapy_disease_sensitivity: 13\n",
      "  f2_2_variant_affects_therapy_disease: 12\n",
      "  f2_2_variant_token_affects_therapy_disease: 11\n",
      "  f2_3_evidential_pmids_variant_resistance: 5\n",
      "  f2_3_evidential_pmids_variant_sensitivity: 5\n",
      "  f2_4_variant_node_property: 5\n",
      "  f3_1_therapies_union_genes: 2\n",
      "  f3_2_therapies_intersection_genes: 5\n",
      "  f3_3_therapies_target_a_not_b: 5\n",
      "  f4_1_target_validation_gene_disease: 11\n",
      "  f4_2_alternative_therapies_from_resistance_genes: 11\n",
      "  f5_1_biomarkers_in_disease: 11\n",
      "  f5_2_therapies_with_biomarker_evidence_in_disease: 11\n",
      "  f6_1_resistance_genes_for_union_therapies_in_disease: 11\n",
      "  f6_2_therapies_target_gene_not_other_with_disease_evidence: 5\n",
      "  f6_3_therapies_target_gene_with_variant_resistance_in_disease: 11\n",
      "  f6_4_alternative_therapies_for_resistance_in_disease: 12\n"
     ]
    }
   ],
   "source": [
    "# Load Test Set\n",
    "\n",
    "test_records = load_test_set(TEST_SUBSET_SIZE)\n",
    "print(f\"Loaded {len(test_records)} test records\")\n",
    "print(\"Template distribution:\")\n",
    "template_counts = Counter(r[\"template_id\"] for r in test_records)\n",
    "for template_id, count in sorted(template_counts.items()):\n",
    "    print(f\"  {template_id}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini components initialized\n",
      "Model: gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gemini Components\n",
    "\n",
    "config = PipelineConfig()\n",
    "gemini_config = GeminiConfig(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    temperature=0.1,\n",
    "    api_key=GEMINI_API_KEY,\n",
    ")\n",
    "\n",
    "expander = GeminiInstructionExpander(config=gemini_config)\n",
    "generator = GeminiCypherGenerator(config=gemini_config)\n",
    "validator = RuleBasedValidator(config=config)\n",
    "executor = Neo4jExecutor(\n",
    "    uri=NEO4J_URI,\n",
    "    user=NEO4J_USER,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = Evaluator(validator, executor, GEMINI_ENCODER)\n",
    "\n",
    "print(\"Gemini components initialized\")\n",
    "print(f\"Model: {gemini_config.model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Gemini: 100%|██████████| 10/10 [00:17<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nGemini evaluation complete: 10 records\n",
      "\\nGemini Metrics:\n",
      "  total: 10\n",
      "  syntactic_validity_pct: 100.00\n",
      "  execution_success_pct: 70.00\n",
      "  semantic_accuracy_pct: 0.00\n",
      "  avg_latency_ms: 867.72\n",
      "  avg_input_tokens: 5164.10\n",
      "  avg_output_tokens: 285.10\n",
      "  total_input_tokens: 51641\n",
      "  total_output_tokens: 2851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Gemini Evaluation\n",
    "\n",
    "from time import sleep\n",
    "import re\n",
    "import random\n",
    "\n",
    "def extract_retry_delay(error_str: str) -> float | None:\n",
    "    \"\"\"Extract retry delay from Gemini API error message.\"\"\"\n",
    "    # Look for \"Please retry in X.XXXs\" pattern\n",
    "    match = re.search(r\"Please retry in ([\\d.]+)s\", error_str, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    # Look for RetryInfo retryDelay in details\n",
    "    match = re.search(r\"'retryDelay':\\s*['\\\"]?(\\d+)s\", error_str, re.IGNORECASE)\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def call_with_retry(func, *args, max_attempts=5, base_delay=1.0, **kwargs):\n",
    "    \"\"\"Call function with exponential backoff, respecting API RetryInfo if available.\"\"\"\n",
    "    last_exception = None\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            last_exception = e\n",
    "            error_str = str(e)\n",
    "            \n",
    "            # Check for rate limit (429)\n",
    "            if \"429\" in error_str or \"RESOURCE_EXHAUSTED\" in error_str:\n",
    "                # Extract retry delay from API response\n",
    "                retry_delay = extract_retry_delay(error_str)\n",
    "                if retry_delay:\n",
    "                    delay = retry_delay + 1.0  # Add buffer\n",
    "                    print(f\"\\\\nRate limit hit. API recommends retry in {retry_delay:.1f}s. Waiting {delay:.1f}s...\")\n",
    "                else:\n",
    "                    # Fallback to exponential backoff with jitter\n",
    "                    delay = base_delay * (2 ** attempt) + random.uniform(0, 1)\n",
    "                    print(f\"\\\\nRate limit hit (attempt {attempt + 1}/{max_attempts}). Waiting {delay:.1f}s...\")\n",
    "                \n",
    "                if attempt < max_attempts - 1:\n",
    "                    sleep(delay)\n",
    "                    continue\n",
    "            \n",
    "            # For other errors, use exponential backoff\n",
    "            if attempt < max_attempts - 1:\n",
    "                delay = base_delay * (2 ** attempt)\n",
    "                print(f\"\\\\nError (attempt {attempt + 1}/{max_attempts}): {type(e).__name__}. Retrying in {delay:.1f}s...\")\n",
    "                sleep(delay)\n",
    "                continue\n",
    "            \n",
    "            # Last attempt failed\n",
    "            raise last_exception\n",
    "    \n",
    "    raise last_exception\n",
    "\n",
    "random.seed(42)  # For jitter consistency\n",
    "\n",
    "gemini_results = []\n",
    "rate_limit_timestamps = []  # Track request timestamps for rate limiting\n",
    "checkpoint_file = EVAL_DIR / \"gemini_results_checkpoint.jsonl\"\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if checkpoint_file.exists():\n",
    "    print(f\"Loading checkpoint from {checkpoint_file}\")\n",
    "    with checkpoint_file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        checkpoint_records = [json.loads(line) for line in f]\n",
    "        gemini_results = checkpoint_records\n",
    "        # Extract processed record IDs\n",
    "        processed_ids = {r[\"id\"] for r in checkpoint_records}\n",
    "        # Filter out already processed records\n",
    "        test_records = [r for r in test_records if r[\"id\"] not in processed_ids]\n",
    "        print(f\"Resuming from checkpoint: {len(checkpoint_records)} already processed, {len(test_records)} remaining\")\n",
    "\n",
    "preview_test_records = test_records[:10]\n",
    "\n",
    "for i, record in enumerate(tqdm(preview_test_records, desc=\"Evaluating Gemini\")):\n",
    "    question = record[\"question\"]\n",
    "    gold_cypher = record[\"cypher\"]\n",
    "    record_id = record[\"id\"]\n",
    "    \n",
    "    # Rate limiting: ensure we don't exceed 15 RPM\n",
    "    current_time = time.time()\n",
    "    rate_limit_timestamps = [\n",
    "        ts for ts in rate_limit_timestamps if current_time - ts < 60\n",
    "    ]  # Keep only timestamps from last minute\n",
    "    \n",
    "    if len(rate_limit_timestamps) >= RATE_LIMIT_RPM:\n",
    "        sleep_time = 60 - (current_time - rate_limit_timestamps[0]) + 1\n",
    "        if sleep_time > 0:\n",
    "            print(f\"\\\\nRate limit approaching, sleeping {sleep_time:.1f}s...\")\n",
    "            sleep(sleep_time)\n",
    "            current_time = time.time()\n",
    "            rate_limit_timestamps = []\n",
    "    \n",
    "    rate_limit_timestamps.append(current_time)\n",
    "    \n",
    "    try:\n",
    "        # Generate instructions and Cypher with retry logic\n",
    "        def _generate_instructions():\n",
    "            return expander.expand_instructions(question)\n",
    "        \n",
    "        def _generate_cypher(inst):\n",
    "            return generator.generate_cypher(inst)\n",
    "        \n",
    "        instructions = call_with_retry(_generate_instructions, max_attempts=5, base_delay=2.0)\n",
    "        generated_cypher = call_with_retry(_generate_cypher, instructions, max_attempts=5, base_delay=2.0)\n",
    "        \n",
    "        # Count tokens for full prompt chain (reconstruct prompts for counting)\n",
    "        from src.pipeline.prompts import CYPHER_PROMPT_TEMPLATE, INSTRUCTION_PROMPT_TEMPLATE, SCHEMA_SNIPPET\n",
    "        instruction_prompt = INSTRUCTION_PROMPT_TEMPLATE.format(\n",
    "            schema=SCHEMA_SNIPPET, question=question.strip()\n",
    "        )\n",
    "        cypher_prompt = CYPHER_PROMPT_TEMPLATE.format(\n",
    "            schema=SCHEMA_SNIPPET, instructions=instructions.strip()\n",
    "        )\n",
    "        full_prompt = instruction_prompt + \"\\\\n\\\\n\" + cypher_prompt\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_result = evaluator.evaluate_single(\n",
    "            question=question,\n",
    "            gold_cypher=gold_cypher,\n",
    "            generated_cypher=generated_cypher,\n",
    "            prompt_text=full_prompt,\n",
    "            model_name=\"gemini\",\n",
    "        )\n",
    "        \n",
    "        # Add metadata\n",
    "        eval_result[\"id\"] = record_id\n",
    "        eval_result[\"question\"] = question\n",
    "        eval_result[\"gold_cypher\"] = gold_cypher\n",
    "        eval_result[\"instructions\"] = instructions\n",
    "        gemini_results.append(eval_result)\n",
    "        \n",
    "        # Checkpoint every 50 records\n",
    "        if (i + 1) % 50 == 0:\n",
    "            with checkpoint_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                for res in gemini_results:\n",
    "                    f.write(json.dumps(res, ensure_ascii=False) + \"\\n\")\n",
    "            print(f\"\\nCheckpoint saved: {len(gemini_results)} records processed\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\nError processing record {record_id}: {e}\")\n",
    "        gemini_results.append({\n",
    "            \"id\": record_id,\n",
    "            \"question\": question,\n",
    "            \"gold_cypher\": gold_cypher,\n",
    "            \"syntactic_valid\": False,\n",
    "            \"execution_success\": False,\n",
    "            \"result_match\": False,\n",
    "            \"generated_cypher\": \"\",\n",
    "            \"error\": f\"Evaluation error: {type(e).__name__}: {e}\",\n",
    "            \"latency_ms\": 0,\n",
    "            \"input_tokens\": 0,\n",
    "            \"output_tokens\": 0,\n",
    "            \"gold_rows\": [],\n",
    "            \"generated_rows\": [],\n",
    "        })\n",
    "\n",
    "# Final checkpoint\n",
    "with checkpoint_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for res in gemini_results:\n",
    "        f.write(json.dumps(res, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\\\nGemini evaluation complete: {len(gemini_results)} records\")\n",
    "gemini_metrics = evaluator.aggregate_metrics(gemini_results)\n",
    "print(\"\\\\nGemini Metrics:\")\n",
    "for key, value in gemini_metrics.items():\n",
    "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen Base Model Evaluation\n",
    "\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Create minimal Qwen prompt template\n",
    "QWEN_MINIMAL_SCHEMA = \"\"\"Graph schema:\n",
    "- Nodes: Gene(symbol), Variant(name), Therapy(name), Disease(name), Biomarker\n",
    "- Relationships: (Variant)-[:VARIANT_OF]->(Gene), (Therapy)-[:TARGETS]->(Gene), (Biomarker)-[:AFFECTS_RESPONSE_TO]->(Therapy)\n",
    "- Properties: effect, disease_name, pmids, moa, ref_sources, ref_ids, ref_urls\n",
    "- Return: Always include LIMIT, no parameters ($variables), use coalesce for arrays\"\"\"\n",
    "\n",
    "QWEN_SYSTEM_PROMPT = f\"\"\"You are an expert Cypher query translator for oncology data.\n",
    "\n",
    "{QWEN_MINIMAL_SCHEMA}\n",
    "\n",
    "Rules:\n",
    "- Return only Cypher query (no markdown, no explanation)\n",
    "- Include RETURN clause and LIMIT\n",
    "- Use toLower() for case-insensitive matching\n",
    "- Wrap arrays with coalesce(..., []) before any()/all()\n",
    "- For disease filters, use token-based CONTAINS matching\"\"\"\n",
    "\n",
    "def format_qwen_prompt(question: str) -> str:\n",
    "    \"\"\"Format question using Qwen chat template.\"\"\"\n",
    "    return f\"\"\"<|im_start|>system\n",
    "{QWEN_SYSTEM_PROMPT}\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{question}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "# Load Qwen model\n",
    "print(\"Loading Qwen model...\")\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"Qwen/Qwen1.5-4B-Instruct\",\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)  # Enable inference optimizations\n",
    "print(\"Qwen model loaded successfully\")\n",
    "\n",
    "# Create evaluator for Qwen (using Qwen's tokenizer for token counting)\n",
    "class QwenEvaluator(Evaluator):\n",
    "    \"\"\"Evaluator that uses Qwen's tokenizer for token counting.\"\"\"\n",
    "    \n",
    "    def __init__(self, validator, executor, qwen_tokenizer):\n",
    "        self.validator = validator\n",
    "        self.executor = executor\n",
    "        self.qwen_tokenizer = qwen_tokenizer\n",
    "    \n",
    "    def evaluate_single(self, question, gold_cypher, generated_cypher, prompt_text, model_name):\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Count tokens using Qwen's tokenizer\n",
    "        # Note: Qwen tokenizer's encode method may or may not support add_special_tokens\n",
    "        try:\n",
    "            input_tokens = len(self.qwen_tokenizer.encode(prompt_text, add_special_tokens=False))\n",
    "            output_tokens = len(self.qwen_tokenizer.encode(generated_cypher, add_special_tokens=False))\n",
    "        except TypeError:\n",
    "            # Fallback if add_special_tokens not supported\n",
    "            input_tokens = len(self.qwen_tokenizer.encode(prompt_text))\n",
    "            output_tokens = len(self.qwen_tokenizer.encode(generated_cypher))\n",
    "        \n",
    "        # Syntactic validation\n",
    "        syntactic_valid, syntax_error = evaluate_cypher_syntax(generated_cypher, self.validator)\n",
    "        \n",
    "        # Execution\n",
    "        execution_success = False\n",
    "        execution_error = None\n",
    "        generated_rows = []\n",
    "        if syntactic_valid:\n",
    "            execution_success, generated_rows, execution_error = evaluate_cypher_execution(\n",
    "                generated_cypher, self.executor\n",
    "            )\n",
    "        \n",
    "        # Get gold results\n",
    "        _, gold_rows, _ = evaluate_cypher_execution(gold_cypher, self.executor)\n",
    "        \n",
    "        # Result comparison\n",
    "        result_match = False\n",
    "        if syntactic_valid and execution_success:\n",
    "            result_match = compare_results(gold_rows, generated_rows)\n",
    "        \n",
    "        latency_ms = (time.perf_counter() - start_time) * 1000\n",
    "        \n",
    "        return {\n",
    "            \"syntactic_valid\": syntactic_valid,\n",
    "            \"execution_success\": execution_success,\n",
    "            \"result_match\": result_match,\n",
    "            \"generated_cypher\": generated_cypher,\n",
    "            \"error\": syntax_error or execution_error,\n",
    "            \"latency_ms\": latency_ms,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"gold_rows\": gold_rows,\n",
    "            \"generated_rows\": generated_rows,\n",
    "        }\n",
    "    \n",
    "    def aggregate_metrics(self, results):\n",
    "        return super().aggregate_metrics(results)\n",
    "\n",
    "# Note: tokenizer will be defined after model loading\n",
    "# qwen_evaluator will be created after model/tokenizer are loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Qwen Evaluation\n",
    "\n",
    "qwen_results = []\n",
    "checkpoint_file_qwen = EVAL_DIR / \"qwen_results_checkpoint.jsonl\"\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if checkpoint_file_qwen.exists():\n",
    "    print(f\"Loading Qwen checkpoint from {checkpoint_file_qwen}\")\n",
    "    with checkpoint_file_qwen.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        checkpoint_records = [json.loads(line) for line in f]\n",
    "        qwen_results = checkpoint_records\n",
    "        processed_ids = {r[\"id\"] for r in checkpoint_records}\n",
    "        test_records_qwen = [r for r in test_records_qwen if r[\"id\"] not in processed_ids]\n",
    "        print(f\"Resuming from checkpoint: {len(checkpoint_records)} already processed, {len(test_records_qwen)} remaining\")\n",
    "\n",
    "for i, record in enumerate(tqdm(test_records_qwen, desc=\"Evaluating Qwen\")):\n",
    "    question = record[\"question\"]\n",
    "    gold_cypher = record[\"cypher\"]\n",
    "    record_id = record[\"id\"]\n",
    "    \n",
    "    try:\n",
    "        # Format prompt\n",
    "        prompt_text = format_qwen_prompt(question)\n",
    "        \n",
    "        # Generate Cypher\n",
    "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract Cypher from response (after assistant tag)\n",
    "        if \"<|im_start|>assistant\" in generated_text:\n",
    "            generated_cypher = generated_text.split(\"<|im_start|>assistant\")[-1].strip()\n",
    "        else:\n",
    "            # If no tag, assume the model output is the Cypher\n",
    "            generated_cypher = generated_text.split(\"<|im_end|>\")[0].strip()\n",
    "        \n",
    "        # Clean up markdown code fences if present\n",
    "        if \"```\" in generated_cypher:\n",
    "            lines = generated_cypher.split(\"\\\\n\")\n",
    "            # Remove code fence lines\n",
    "            cleaned = [l for l in lines if not l.strip().startswith(\"```\")]\n",
    "            generated_cypher = \"\\\\n\".join(cleaned).strip()\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_result = qwen_evaluator.evaluate_single(\n",
    "            question=question,\n",
    "            gold_cypher=gold_cypher,\n",
    "            generated_cypher=generated_cypher,\n",
    "            prompt_text=prompt_text,\n",
    "            model_name=\"qwen\",\n",
    "        )\n",
    "        \n",
    "        # Add metadata\n",
    "        eval_result[\"id\"] = record_id\n",
    "        eval_result[\"question\"] = question\n",
    "        eval_result[\"gold_cypher\"] = gold_cypher\n",
    "        qwen_results.append(eval_result)\n",
    "        \n",
    "        # Checkpoint every 50 records\n",
    "        if (i + 1) % 50 == 0:\n",
    "            with checkpoint_file_qwen.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                for res in qwen_results:\n",
    "                    f.write(json.dumps(res, ensure_ascii=False) + \"\\n\")\n",
    "            print(f\"\\nCheckpoint saved: {len(qwen_results)} records processed\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\nError processing record {record_id}: {e}\")\n",
    "        qwen_results.append({\n",
    "            \"id\": record_id,\n",
    "            \"question\": question,\n",
    "            \"gold_cypher\": gold_cypher,\n",
    "            \"syntactic_valid\": False,\n",
    "            \"execution_success\": False,\n",
    "            \"result_match\": False,\n",
    "            \"generated_cypher\": \"\",\n",
    "            \"error\": f\"Evaluation error: {type(e).__name__}: {e}\",\n",
    "            \"latency_ms\": 0,\n",
    "            \"input_tokens\": 0,\n",
    "            \"output_tokens\": 0,\n",
    "            \"gold_rows\": [],\n",
    "            \"generated_rows\": [],\n",
    "        })\n",
    "\n",
    "# Final checkpoint\n",
    "with checkpoint_file_qwen.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for res in qwen_results:\n",
    "        f.write(json.dumps(res, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\\\nQwen evaluation complete: {len(qwen_results)} records\")\n",
    "qwen_metrics = qwen_evaluator.aggregate_metrics(qwen_results)\n",
    "print(\"\\\\nQwen Metrics:\")\n",
    "for key, value in qwen_metrics.items():\n",
    "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Analysis & Comparison\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Aggregate metrics\n",
    "gemini_metrics = evaluator.aggregate_metrics(gemini_results)\n",
    "qwen_metrics = qwen_evaluator.aggregate_metrics(qwen_results)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    \"Metric\": [\n",
    "        \"Syntactic Validity (%)\",\n",
    "        \"Execution Success (%)\",\n",
    "        \"Semantic Accuracy (%)\",\n",
    "        \"Avg Latency (ms)\",\n",
    "        \"Avg Input Tokens\",\n",
    "        \"Avg Output Tokens\",\n",
    "        \"Total Input Tokens\",\n",
    "        \"Total Output Tokens\",\n",
    "    ],\n",
    "    \"Gemini 2.5 Flash-Lite\": [\n",
    "        gemini_metrics.get(\"syntactic_validity_pct\", 0),\n",
    "        gemini_metrics.get(\"execution_success_pct\", 0),\n",
    "        gemini_metrics.get(\"semantic_accuracy_pct\", 0),\n",
    "        gemini_metrics.get(\"avg_latency_ms\", 0),\n",
    "        gemini_metrics.get(\"avg_input_tokens\", 0),\n",
    "        gemini_metrics.get(\"avg_output_tokens\", 0),\n",
    "        gemini_metrics.get(\"total_input_tokens\", 0),\n",
    "        gemini_metrics.get(\"total_output_tokens\", 0),\n",
    "    ],\n",
    "    \"Qwen3-4B Base\": [\n",
    "        qwen_metrics.get(\"syntactic_validity_pct\", 0),\n",
    "        qwen_metrics.get(\"execution_success_pct\", 0),\n",
    "        qwen_metrics.get(\"semantic_accuracy_pct\", 0),\n",
    "        qwen_metrics.get(\"avg_latency_ms\", 0),\n",
    "        qwen_metrics.get(\"avg_input_tokens\", 0),\n",
    "        qwen_metrics.get(\"avg_output_tokens\", 0),\n",
    "        qwen_metrics.get(\"total_input_tokens\", 0),\n",
    "        qwen_metrics.get(\"total_output_tokens\", 0),\n",
    "    ],\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"BASELINE EVALUATION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"\\\\n\")\n",
    "\n",
    "# Calculate token efficiency improvement\n",
    "gemini_total = gemini_metrics.get(\"total_input_tokens\", 0) + gemini_metrics.get(\"total_output_tokens\", 0)\n",
    "qwen_total = qwen_metrics.get(\"total_input_tokens\", 0) + qwen_metrics.get(\"total_output_tokens\", 0)\n",
    "if gemini_total > 0:\n",
    "    token_reduction_pct = ((gemini_total - qwen_total) / gemini_total) * 100\n",
    "    print(f\"Token usage reduction (Qwen vs Gemini): {token_reduction_pct:.1f}%\")\n",
    "    print(f\"  Gemini total: {gemini_total} tokens\")\n",
    "    print(f\"  Qwen total: {qwen_total} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nPartial matches (syntax + exec pass, result mismatch):\n",
      "  Gemini: 7\n",
      "\\nPartial matches saved to:\n",
      "  C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\\finetuning\\eval\\partial_matches_gemini.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Identify Partial Matches (syntactic + execution pass but result mismatch)\n",
    "\n",
    "def extract_partial_matches(results: list[dict[str, Any]], model_name: str) -> list[dict[str, Any]]:\n",
    "    \"\"\"Extract records where syntactic and execution pass but result doesn't match.\"\"\"\n",
    "    partial = []\n",
    "    for r in results:\n",
    "        if r[\"syntactic_valid\"] and r[\"execution_success\"] and not r[\"result_match\"]:\n",
    "            partial.append({\n",
    "                \"id\": r[\"id\"],\n",
    "                \"question\": r[\"question\"],\n",
    "                \"gold_cypher\": r[\"gold_cypher\"],\n",
    "                \"generated_cypher\": r[\"generated_cypher\"],\n",
    "                \"gold_rows\": r.get(\"gold_rows\", []),\n",
    "                \"generated_rows\": r.get(\"generated_rows\", []),\n",
    "                \"error\": r.get(\"error\"),\n",
    "            })\n",
    "    return partial\n",
    "\n",
    "gemini_partial = extract_partial_matches(gemini_results, \"gemini\")\n",
    "print(\"\\\\nPartial matches (syntax + exec pass, result mismatch):\")\n",
    "print(f\"  Gemini: {len(gemini_partial)}\")\n",
    "\n",
    "# Only process Qwen if results are available\n",
    "if 'qwen_results' in globals() and qwen_results:\n",
    "    qwen_partial = extract_partial_matches(qwen_results, \"qwen\")\n",
    "    print(f\"  Qwen: {len(qwen_partial)}\")\n",
    "else:\n",
    "    qwen_partial = []\n",
    "\n",
    "# Save partial matches for inspection\n",
    "partial_gemini_file = EVAL_DIR / \"partial_matches_gemini.jsonl\"\n",
    "with partial_gemini_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for record in gemini_partial:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"\\nPartial matches saved to:\")\n",
    "print(f\"  {partial_gemini_file}\")\n",
    "\n",
    "if qwen_partial:\n",
    "    partial_qwen_file = EVAL_DIR / \"partial_matches_qwen.jsonl\"\n",
    "    with partial_qwen_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for record in qwen_partial:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"  {partial_qwen_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== GEMINI RESULTS SUMMARY ===\n",
      "               id                                                                                           question syntactic_valid execution_success result_match  gold_rows  gen_rows                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     error\n",
      "F5.2-000167-S1-P2                           Show drugs with variant-based evidence in Chronic Myelogenous Leukaemia.               ✓                 ✓            ✗        100         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "F5.2-000070-S1-P2                                  Show drugs with variant-based evidence in Infantile Fibrosarcoma.               ✓                 ✗            ✗          6         0                                                                                                                                                                                                                           PipelineError: Neo4j execution failed: CypherSyntaxError: {neo4j_code: Neo.ClientError.Statement.SyntaxError} {message: Variable `g` not defined (line 5, column 39 (offset: 262))\\n\"  CASE WHEN b:Gene THEN b.symbol ELSE g.symbol END AS gene_symbol,\"\\n                                       ^} {gql_status: 42001} {gql_status_description: error: syntax error or access rule violation - invalid syntax}\n",
      "F5.2-000034-S1-P3                         List treatments supported by variant evidence in WHO Grade II Astrocytoma.               ✓                 ✗            ✗          2         0 PipelineError: Neo4j execution failed: CypherSyntaxError: {neo4j_code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'GROUP': expected ',', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FINISH', 'FOREACH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WHERE', 'WITH' or <EOF> (line 28, column 1 (offset: 910))\\n\"GROUP BY variant_name, gene_symbol, therapy_name, effect, disease_name\"\\n ^} {gql_status: 42001} {gql_status_description: error: syntax error or access rule violation - invalid syntax}\n",
      "   F5.2-000092-P3 List treatments supported by variant evidence in B-lymphoblastic Leukemia/lymphoma With TCF3-PBX1.               ✓                 ✓            ✗          2         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "F5.2-000096-S1-P1                           Which therapies have variant biomarkers in Carcinoma Of Urinary Bladder?               ✓                 ✓            ✗         49         2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "F5.2-000032-S1-P2                           Show drugs with variant-based evidence in Ureteral Small Cell Carcinoma.               ✓                 ✗            ✗          2         0                                                               PipelineError: Neo4j execution failed: CypherSyntaxError: {neo4j_code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'GROUP': expected ',', 'ORDER BY', 'CALL', 'CREATE', 'LOAD CSV', 'DELETE', 'DETACH', 'FINISH', 'FOREACH', 'INSERT', 'LIMIT', 'MATCH', 'MERGE', 'NODETACH', 'OFFSET', 'OPTIONAL', 'REMOVE', 'RETURN', 'SET', 'SKIP', 'UNION', 'UNWIND', 'USE', 'WHERE', 'WITH' or <EOF> (line 34, column 1 (offset: 868))\\n\"GROUP BY\"\\n ^} {gql_status: 42001} {gql_status_description: error: syntax error or access rule violation - invalid syntax}\n",
      "F5.2-000170-S1-P1                            Which therapies have variant biomarkers in Vulvar Epidermoid Carcinoma?               ✓                 ✓            ✗          1         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "   F5.2-000093-P3                                       List treatments supported by variant evidence in Myofibroma.               ✓                 ✓            ✗          1         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "   F5.2-000048-S1            List therapies with variant-level biomarkers in Minimally Invasive Lung Adenocarcinoma.               ✓                 ✓            ✗          1        39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "F5.2-000012-S1-P3                                List treatments supported by variant evidence in B-ALL With IAMP21.               ✓                 ✓            ✗          2         0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "\\n(Qwen results not available - skipping Qwen summary)\n",
      "Gemini summary saved to: C:\\Users\\ishui\\Desktop\\OncoGraph\\OncoGraph Agent\\finetuning\\eval\\gemini_results_summary.csv\n",
      "\\n====================================================================================================\n",
      "DETAILED INSPECTION: GEMINI PARTIAL MATCHES (syntax + exec pass, result mismatch)\n",
      "====================================================================================================\n",
      "\\n--- Mismatch #1 ---\n",
      "====================================================================================================\n",
      "ID: F5.2-000167-S1-P2\n",
      "Question: Show drugs with variant-based evidence in Chronic Myelogenous Leukaemia.\n",
      "\\n----------------------------------------------------------------------------------------------------\n",
      "STATUS: Syntax: ✗ | Exec: ✗ | Match: ✗ | Latency: 0ms | Tokens: 0/0\n",
      "\\n====================================================================================================\n",
      "📋 GOLD CYPHER (Expected Reference)\n",
      "====================================================================================================\n",
      "```cypher\n",
      "MATCH (v:Variant)-[rel:AFFECTS_RESPONSE_TO]->(t:Therapy)\n",
      "WHERE (\n",
      "    toLower(rel.disease_name) CONTAINS 'chronic' AND\n",
      "    toLower(rel.disease_name) CONTAINS 'myeloid' AND\n",
      "    toLower(rel.disease_name) CONTAINS 'leukemia'\n",
      "  )\n",
      "OPTIONAL MATCH (v)-[:VARIANT_OF]->(g:Gene)\n",
      "RETURN\n",
      "  v.name AS variant_name,\n",
      "  g.symbol AS gene_symbol,\n",
      "  t.name AS therapy_name,\n",
      "  rel.effect AS effect,\n",
      "  rel.disease_name AS disease_name,\n",
      "  coalesce(rel.pmids, []) AS pmids\n",
      "LIMIT 100\n",
      "\n",
      "```\n",
      "\\n📊 GOLD RESULTS: 100 row(s)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [  1] variant_name='ABL1 T315I', gene_symbol='ABL1', therapy_name='Asciminib', effect='sensitivity', disease_name='Chronic Myeloid Leukemia', pmids=['31826340']\n",
      "  [  2] variant_name='BCR BCR::ABL1 Fusion', gene_symbol='BCR', therapy_name='Asciminib', effect='sensitivity', disease_name='Chronic Myeloid Leukemia', pmids=['38820078']\n",
      "  [  3] variant_name='BCR BCR::ABL1 Fusion AND ABL1 D276G', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [  4] variant_name='BCR BCR::ABL1 Fusion AND ABL1 E255K', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [  5] variant_name='BCR BCR::ABL1 Fusion AND ABL1 E255V', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [  6] variant_name='BCR BCR::ABL1 Fusion AND ABL1 E255V AND ABL1 V299L', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [  7] variant_name='BCR BCR::ABL1 Fusion AND ABL1 E279K', gene_symbol='BCR', therapy_name='Axitinib', effect='sensitivity', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [  8] variant_name='BCR BCR::ABL1 Fusion AND ABL1 E292L', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [  9] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F311I', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [ 10] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F317L', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [ 11] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F317L AND ABL1 F359V', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [ 12] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F317R', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [ 13] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F317V', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [ 14] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F359I', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [ 15] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F359V', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [ 16] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F359V AND ABL1 V299L', gene_symbol='BCR', therapy_name='Axitinib', effect='sensitivity', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [ 17] variant_name='BCR BCR::ABL1 Fusion AND ABL1 F486S', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [ 18] variant_name='BCR BCR::ABL1 Fusion AND ABL1 G250E', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['26582647']\n",
      "  [ 19] variant_name='BCR BCR::ABL1 Fusion AND ABL1 H396P', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  [ 20] variant_name='BCR BCR::ABL1 Fusion AND ABL1 H396R', gene_symbol='BCR', therapy_name='Axitinib', effect='resistance', disease_name='Chronic Myeloid Leukemia', pmids=['25686603']\n",
      "  ... (80 more rows)\n",
      "\\n====================================================================================================\n",
      "🔧 GENERATED CYPHER (Model Output)\n",
      "====================================================================================================\n",
      "```cypher\n",
      "MATCH (b:Biomarker)-[rel:AFFECTS_RESPONSE_TO]->(t:Therapy)\n",
      "WHERE (\n",
      "  toLower(t.name) = toLower('dasatinib') OR\n",
      "  toLower(t.name) = toLower('nilotinib') OR\n",
      "  toLower(t.name) = toLower('bosutinib') OR\n",
      "  toLower(t.name) = toLower('ponatinib') OR\n",
      "  toLower(t.name) = toLower('imatinib') OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('dasatinib')) OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('nilotinib')) OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('bosutinib')) OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('ponatinib')) OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('imatinib'))\n",
      ")\n",
      "AND toLower(rel.disease_name) CONTAINS toLower('chronic myelogenous leukaemia')\n",
      "OPTIONAL MATCH (b)-[:VARIANT_OF]->(g:Gene)\n",
      "WITH\n",
      "  CASE WHEN b:Variant THEN coalesce(b.name, b.hgvs_p) ELSE NULL END AS variant_name,\n",
      "  CASE WHEN b:Gene THEN b.symbol ELSE g.symbol END AS gene_symbol,\n",
      "  t.name AS therapy_name,\n",
      "  rel.effect AS effect,\n",
      "  rel.disease_name AS disease_name,\n",
      "  coalesce(rel.pmids, []) AS pmids\n",
      "WHERE gene_symbol IS NOT NULL OR variant_name IS NOT NULL\n",
      "WITH\n",
      "  variant_name,\n",
      "  gene_symbol,\n",
      "  therapy_name,\n",
      "  effect,\n",
      "  disease_name,\n",
      "  collect(pmids) AS pmid_lists\n",
      "WITH\n",
      "  variant_name,\n",
      "  gene_symbol,\n",
      "  therapy_name,\n",
      "  effect,\n",
      "  disease_name,\n",
      "  reduce(allp = [], lst IN pmid_lists | allp + lst) AS pmids\n",
      "RETURN\n",
      "  variant_name,\n",
      "  gene_symbol,\n",
      "  therapy_name,\n",
      "  effect,\n",
      "  disease_name,\n",
      "  pmids\n",
      "LIMIT 100\n",
      "```\n",
      "\\n📊 GENERATED RESULTS: 0 row(s)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  (no results)\n",
      "\\n\n",
      "\\n--- Mismatch #2 ---\n",
      "====================================================================================================\n",
      "ID: F5.2-000092-P3\n",
      "Question: List treatments supported by variant evidence in B-lymphoblastic Leukemia/lymphoma With TCF3-PBX1.\n",
      "\\n----------------------------------------------------------------------------------------------------\n",
      "STATUS: Syntax: ✗ | Exec: ✗ | Match: ✗ | Latency: 0ms | Tokens: 0/0\n",
      "\\n====================================================================================================\n",
      "📋 GOLD CYPHER (Expected Reference)\n",
      "====================================================================================================\n",
      "```cypher\n",
      "MATCH (v:Variant)-[rel:AFFECTS_RESPONSE_TO]->(t:Therapy)\n",
      "WHERE (\n",
      "    toLower(rel.disease_name) CONTAINS 'b-lymphoblastic' AND\n",
      "    toLower(rel.disease_name) CONTAINS 'leukemia/lymphoma' AND\n",
      "    toLower(rel.disease_name) CONTAINS 'with' AND\n",
      "    toLower(rel.disease_name) CONTAINS 'tcf3-pbx1'\n",
      "  )\n",
      "OPTIONAL MATCH (v)-[:VARIANT_OF]->(g:Gene)\n",
      "RETURN\n",
      "  v.name AS variant_name,\n",
      "  g.symbol AS gene_symbol,\n",
      "  t.name AS therapy_name,\n",
      "  rel.effect AS effect,\n",
      "  rel.disease_name AS disease_name,\n",
      "  coalesce(rel.pmids, []) AS pmids\n",
      "LIMIT 100\n",
      "\n",
      "```\n",
      "\\n📊 GOLD RESULTS: 2 row(s)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [  1] variant_name='TCF3 TCF3::PBX1 Fusion', gene_symbol='TCF3', therapy_name='HyperCVAD Regimen', effect='sensitivity', disease_name='B-lymphoblastic Leukemia/lymphoma With TCF3-PBX1', pmids=['32955970']\n",
      "  [  2] variant_name='TCF3 TCF3::PBX1 Fusion', gene_symbol='TCF3', therapy_name='NCT00137111', effect='sensitivity', disease_name='B-lymphoblastic Leukemia/lymphoma With TCF3-PBX1', pmids=['19282835']\n",
      "\\n====================================================================================================\n",
      "🔧 GENERATED CYPHER (Model Output)\n",
      "====================================================================================================\n",
      "```cypher\n",
      "MATCH (b:Biomarker)-[rel:AFFECTS_RESPONSE_TO]->(t:Therapy)\n",
      "WHERE (toLower(t.name) CONTAINS toLower('treatment') OR any(s IN coalesce(t.synonyms, []) WHERE toLower(s) CONTAINS toLower('treatment')))\n",
      "AND toLower(rel.disease_name) CONTAINS toLower('b-lymphoblastic leukemia/lymphoma')\n",
      "OPTIONAL MATCH (b)-[:VARIANT_OF]->(g:Gene)\n",
      "WHERE (b:Variant AND (toLower(b.name) CONTAINS toLower('tcf3-pbx1') OR any(s IN coalesce(b.synonyms, []) WHERE toLower(s) CONTAINS toLower('tcf3-pbx1')) OR toLower(b.hgvs_p) CONTAINS toLower('p.tcf3-pbx1')))\n",
      "RETURN\n",
      "  CASE WHEN b:Variant THEN coalesce(b.name, b.hgvs_p) ELSE NULL END AS variant_name,\n",
      "  CASE WHEN b:Gene THEN b.symbol ELSE g.symbol END AS gene_symbol,\n",
      "  t.name AS therapy_name,\n",
      "  rel.effect AS effect,\n",
      "  rel.disease_name AS disease_name,\n",
      "  coalesce(rel.pmids, []) AS pmids\n",
      "LIMIT 100\n",
      "```\n",
      "\\n📊 GENERATED RESULTS: 0 row(s)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  (no results)\n",
      "\\n\n",
      "\\n--- Mismatch #3 ---\n",
      "====================================================================================================\n",
      "ID: F5.2-000096-S1-P1\n",
      "Question: Which therapies have variant biomarkers in Carcinoma Of Urinary Bladder?\n",
      "\\n----------------------------------------------------------------------------------------------------\n",
      "STATUS: Syntax: ✗ | Exec: ✗ | Match: ✗ | Latency: 0ms | Tokens: 0/0\n",
      "\\n====================================================================================================\n",
      "📋 GOLD CYPHER (Expected Reference)\n",
      "====================================================================================================\n",
      "```cypher\n",
      "MATCH (v:Variant)-[rel:AFFECTS_RESPONSE_TO]->(t:Therapy)\n",
      "WHERE (\n",
      "    toLower(rel.disease_name) CONTAINS 'bladder' AND\n",
      "    toLower(rel.disease_name) CONTAINS 'carcinoma'\n",
      "  )\n",
      "OPTIONAL MATCH (v)-[:VARIANT_OF]->(g:Gene)\n",
      "RETURN\n",
      "  v.name AS variant_name,\n",
      "  g.symbol AS gene_symbol,\n",
      "  t.name AS therapy_name,\n",
      "  rel.effect AS effect,\n",
      "  rel.disease_name AS disease_name,\n",
      "  coalesce(rel.pmids, []) AS pmids\n",
      "LIMIT 100\n",
      "\n",
      "```\n",
      "\\n📊 GOLD RESULTS: 49 row(s)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [  1] variant_name='CD274 Expression', gene_symbol='CD274', therapy_name='Atezolizumab', effect='sensitivity', disease_name='Bladder Urothelial Carcinoma', pmids=['29268948']\n",
      "  [  2] variant_name='RAF1 Amplification', gene_symbol='RAF1', therapy_name='B-Raf/VEGFR-2 Inhibitor RAF265', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['34554931']\n",
      "  [  3] variant_name='ERBB2 D769H', gene_symbol='ERBB2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [  4] variant_name='ERBB2 R678L', gene_symbol='ERBB2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [  5] variant_name='ERBB2 S310F', gene_symbol='ERBB2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [  6] variant_name='ERBB2 S310F AND NOT ERBB2 T306M', gene_symbol='ERBB2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [  7] variant_name='ERBB2 V777M', gene_symbol='ERBB2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [  8] variant_name='ERBB2 V842I', gene_symbol='ERBB2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [  9] variant_name='ERCC2 D257N', gene_symbol='ERCC2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [ 10] variant_name='ERCC2 E86Q', gene_symbol='ERCC2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [ 11] variant_name='ERCC2 N238S', gene_symbol='ERCC2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [ 12] variant_name='ERCC2 S44L', gene_symbol='ERCC2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [ 13] variant_name='ERCC2 T484M', gene_symbol='ERCC2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [ 14] variant_name='ERCC2 Y72C', gene_symbol='ERCC2', therapy_name='Chemotherapy', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['25636205']\n",
      "  [ 15] variant_name='ERCC1 Expression', gene_symbol='ERCC1', therapy_name='Cisplatin', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['26162296']\n",
      "  [ 16] variant_name='FGFR1 Expression', gene_symbol='FGFR1', therapy_name='Dovitinib', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['21119661']\n",
      "  [ 17] variant_name='FGFR3 Overexpression', gene_symbol='FGFR3', therapy_name='Dovitinib', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['21119661']\n",
      "  [ 18] variant_name='FGFR2 FGFR2::? Fusion', gene_symbol='FGFR2', therapy_name='Erdafitinib', effect='sensitivity', disease_name='Bladder Urothelial Carcinoma', pmids=['31088831']\n",
      "  [ 19] variant_name='FGFR2 FGFR2::v Fusion', gene_symbol='FGFR2', therapy_name='Erdafitinib', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['31340094']\n",
      "  [ 20] variant_name='FGFR3 FGFR3::v Fusion', gene_symbol='FGFR3', therapy_name='Erdafitinib', effect='sensitivity', disease_name='Bladder Carcinoma', pmids=['31340094']\n",
      "  ... (29 more rows)\n",
      "\\n====================================================================================================\n",
      "🔧 GENERATED CYPHER (Model Output)\n",
      "====================================================================================================\n",
      "```cypher\n",
      "MATCH (b:Biomarker)-[rel:AFFECTS_RESPONSE_TO]->(t:Therapy)\n",
      "WHERE (\n",
      "  toLower(t.name) = toLower('gemcitabine') OR\n",
      "  toLower(t.name) = toLower('cisplatin') OR\n",
      "  toLower(t.name) = toLower('carboplatin') OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('gemcitabine')) OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('cisplatin')) OR\n",
      "  any(s IN coalesce(t.synonyms, []) WHERE toLower(s) = toLower('carboplatin'))\n",
      ")\n",
      "AND toLower(rel.effect) = 'sensitivity'\n",
      "AND toLower(rel.disease_name) CONTAINS toLower('urinary bladder')\n",
      "OPTIONAL MATCH (b)-[:VARIANT_OF]->(g:Gene)\n",
      "WITH\n",
      "  CASE WHEN b:Variant THEN coalesce(b.name, b.hgvs_p) ELSE NULL END AS variant_name,\n",
      "  CASE WHEN b:Gene THEN b.symbol ELSE g.symbol END AS gene_symbol,\n",
      "  t.name AS therapy_name,\n",
      "  rel.effect AS effect,\n",
      "  rel.disease_name AS disease_name,\n",
      "  coalesce(rel.pmids, []) AS pmids\n",
      "WHERE gene_symbol IS NOT NULL OR variant_name IS NOT NULL\n",
      "WITH\n",
      "  variant_name,\n",
      "  gene_symbol,\n",
      "  therapy_name,\n",
      "  effect,\n",
      "  disease_name,\n",
      "  collect(pmids) AS pmid_lists\n",
      "WITH\n",
      "  variant_name,\n",
      "  gene_symbol,\n",
      "  therapy_name,\n",
      "  effect,\n",
      "  disease_name,\n",
      "  reduce(allp = [], lst IN pmid_lists | allp + lst) AS pmids\n",
      "RETURN\n",
      "  variant_name,\n",
      "  gene_symbol,\n",
      "  therapy_name,\n",
      "  effect,\n",
      "  disease_name,\n",
      "  pmids\n",
      "LIMIT 100\n",
      "```\n",
      "\\n📊 GENERATED RESULTS: 2 row(s)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [  1] variant_name='FGFR3 Mutation', gene_symbol='FGFR3', therapy_name='Cisplatin', effect='sensitivity', disease_name='Urinary Bladder Cancer', pmids=['29941343']\n",
      "  [  2] variant_name='FGFR3 Mutation', gene_symbol='FGFR3', therapy_name='Gemcitabine', effect='sensitivity', disease_name='Urinary Bladder Cancer', pmids=['29941343']\n",
      "\\n\n"
     ]
    }
   ],
   "source": [
    "# Detailed Result Inspection\n",
    "\n",
    "def inspect_record(record: dict[str, Any], max_rows_display: int = 20):\n",
    "    \"\"\"Pretty-print a record for detailed inspection with Cypher queries paired with their results.\"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(f\"ID: {record.get('id', 'N/A')}\")\n",
    "    print(f\"Question: {record.get('question', 'N/A')}\")\n",
    "    print(\"\\\\n\" + \"-\"*100)\n",
    "    \n",
    "    # Compact status header\n",
    "    status_parts = []\n",
    "    status_parts.append(\"Syntax: \" + (\"✓\" if record.get('syntactic_valid') else \"✗\"))\n",
    "    status_parts.append(\"Exec: \" + (\"✓\" if record.get('execution_success') else \"✗\"))\n",
    "    status_parts.append(\"Match: \" + (\"✓\" if record.get('result_match') else \"✗\"))\n",
    "    status_parts.append(f\"Latency: {record.get('latency_ms', 0):.0f}ms\")\n",
    "    status_parts.append(f\"Tokens: {record.get('input_tokens', 0)}/{record.get('output_tokens', 0)}\")\n",
    "    print(\"STATUS: \" + \" | \".join(status_parts))\n",
    "    if record.get('error'):\n",
    "        print(f\"ERROR: {record.get('error')}\")\n",
    "    \n",
    "    gold_cypher = record.get('gold_cypher', '')\n",
    "    gen_cypher = record.get('generated_cypher', '')\n",
    "    gold_rows = record.get('gold_rows', [])\n",
    "    gen_rows = record.get('generated_rows', [])\n",
    "    \n",
    "    # Show GOLD CYPHER with its results together\n",
    "    print(\"\\\\n\" + \"=\"*100)\n",
    "    print(\"📋 GOLD CYPHER (Expected Reference)\")\n",
    "    print(\"=\"*100)\n",
    "    if gold_cypher:\n",
    "        print(\"```cypher\")\n",
    "        for i, line in enumerate(gold_cypher.split('\\\\n'), 1):\n",
    "            print(f\"{line}\")\n",
    "        print(\"```\")\n",
    "    else:\n",
    "        print(\"  (empty)\")\n",
    "    \n",
    "    print(f\"\\\\n📊 GOLD RESULTS: {len(gold_rows)} row(s)\")\n",
    "    print(\"-\"*100)\n",
    "    if gold_rows:\n",
    "        for i, row in enumerate(gold_rows[:max_rows_display], 1):\n",
    "            # Format row nicely as key: value pairs\n",
    "            row_str = \", \".join([f\"{k}={v!r}\" for k, v in row.items()])\n",
    "            print(f\"  [{i:3d}] {row_str}\")\n",
    "        if len(gold_rows) > max_rows_display:\n",
    "            print(f\"  ... ({len(gold_rows) - max_rows_display} more rows)\")\n",
    "    else:\n",
    "        print(\"  (no results)\")\n",
    "    \n",
    "    # Show GENERATED CYPHER with its results together\n",
    "    print(\"\\\\n\" + \"=\"*100)\n",
    "    print(\"🔧 GENERATED CYPHER (Model Output)\")\n",
    "    print(\"=\"*100)\n",
    "    if gen_cypher:\n",
    "        print(\"```cypher\")\n",
    "        for i, line in enumerate(gen_cypher.split('\\\\n'), 1):\n",
    "            print(f\"{line}\")\n",
    "        print(\"```\")\n",
    "    else:\n",
    "        print(\"  (empty)\")\n",
    "    \n",
    "    print(f\"\\\\n📊 GENERATED RESULTS: {len(gen_rows)} row(s)\")\n",
    "    print(\"-\"*100)\n",
    "    if gen_rows:\n",
    "        for i, row in enumerate(gen_rows[:max_rows_display], 1):\n",
    "            row_str = \", \".join([f\"{k}={v!r}\" for k, v in row.items()])\n",
    "            print(f\"  [{i:3d}] {row_str}\")\n",
    "        if len(gen_rows) > max_rows_display:\n",
    "            print(f\"  ... ({len(gen_rows) - max_rows_display} more rows)\")\n",
    "    else:\n",
    "        print(\"  (no results)\")\n",
    "    \n",
    "    # Show comparison only if both executed successfully but don't match\n",
    "    if record.get('syntactic_valid') and record.get('execution_success') and not record.get('result_match'):\n",
    "        print(\"\\\\n\" + \"=\"*100)\n",
    "        print(\"🔍 RESULT COMPARISON\")\n",
    "        print(\"=\"*100)\n",
    "        print(f\"Row counts: Gold={len(gold_rows)}, Generated={len(gen_rows)}\")\n",
    "        \n",
    "        if len(gold_rows) != len(gen_rows):\n",
    "            print(f\"⚠️  Row count mismatch!\")\n",
    "        \n",
    "        # Identify differences\n",
    "        if gold_rows and gen_rows:\n",
    "            gold_set = {tuple(sorted(r.items())) for r in gold_rows}\n",
    "            gen_set = {tuple(sorted(r.items())) for r in gen_rows}\n",
    "            missing_in_gen = gold_set - gen_set\n",
    "            extra_in_gen = gen_set - gold_set\n",
    "            \n",
    "            if missing_in_gen:\n",
    "                print(f\"\\\\n❌ Missing in generated ({len(missing_in_gen)} rows):\")\n",
    "                for j, row_tuple in enumerate(list(missing_in_gen)[:5], 1):\n",
    "                    row_dict = dict(row_tuple)\n",
    "                    row_str = \", \".join([f\"{k}={v!r}\" for k, v in row_dict.items()])\n",
    "                    print(f\"  {j}. {row_str}\")\n",
    "            \n",
    "            if extra_in_gen:\n",
    "                print(f\"\\\\n➕ Extra in generated ({len(extra_in_gen)} rows):\")\n",
    "                for j, row_tuple in enumerate(list(extra_in_gen)[:5], 1):\n",
    "                    row_dict = dict(row_tuple)\n",
    "                    row_str = \", \".join([f\"{k}={v!r}\" for k, v in row_dict.items()])\n",
    "                    print(f\"  {j}. {row_str}\")\n",
    "            \n",
    "            if not missing_in_gen and not extra_in_gen and len(gold_rows) == len(gen_rows):\n",
    "                print(\"⚠️  Row sets are identical but comparison failed - possible harness issue\")\n",
    "        elif not gold_rows and not gen_rows:\n",
    "            print(\"✓ Both queries returned empty results\")\n",
    "        else:\n",
    "            print(f\"⚠️  One query returned results, the other didn't\")\n",
    "    \n",
    "    print(\"\\\\n\")\n",
    "\n",
    "# Create a summary DataFrame for easy browsing\n",
    "def create_inspection_summary(results: list[dict[str, Any]], model_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Create a readable summary DataFrame from results.\"\"\"\n",
    "    summary_data = []\n",
    "    for r in results:\n",
    "        # Safely handle error field (can be None, empty string, or actual error message)\n",
    "        error_val = r.get(\"error\") or \"\"\n",
    "        error_str = error_val\n",
    "        \n",
    "        # Safely handle question field\n",
    "        question_val = r.get(\"question\") or \"\"\n",
    "        question_str = question_val\n",
    "        \n",
    "        summary_data.append({\n",
    "            \"id\": r.get(\"id\", \"\"),\n",
    "            \"question\": question_str,\n",
    "            \"syntactic_valid\": \"✓\" if r.get(\"syntactic_valid\") else \"✗\",\n",
    "            \"execution_success\": \"✓\" if r.get(\"execution_success\") else \"✗\",\n",
    "            \"result_match\": \"✓\" if r.get(\"result_match\") else \"✗\",\n",
    "            \"gold_rows\": len(r.get(\"gold_rows\", [])),\n",
    "            \"gen_rows\": len(r.get(\"generated_rows\", [])),\n",
    "            \"error\": error_str,\n",
    "        })\n",
    "    return pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\\\n=== GEMINI RESULTS SUMMARY ===\")\n",
    "gemini_summary = create_inspection_summary(gemini_results, \"gemini\")\n",
    "print(gemini_summary.to_string(index=False))\n",
    "\n",
    "# Save readable summaries\n",
    "gemini_summary.to_csv(EVAL_DIR / \"gemini_results_summary.csv\", index=False)\n",
    "\n",
    "# Check if Qwen results are available\n",
    "if 'qwen_results' in globals() and qwen_results:\n",
    "    print(\"\\\\n\\\\n=== QWEN RESULTS SUMMARY ===\")\n",
    "    qwen_summary = create_inspection_summary(qwen_results, \"qwen\")\n",
    "    print(qwen_summary.to_string(index=False))\n",
    "    qwen_summary.to_csv(EVAL_DIR / \"qwen_results_summary.csv\", index=False)\n",
    "    print(f\"\\\\nReadable summaries saved to CSV files in {EVAL_DIR}\")\n",
    "else:\n",
    "    print(f\"\\\\n(Qwen results not available - skipping Qwen summary)\")\n",
    "    print(f\"Gemini summary saved to: {EVAL_DIR / 'gemini_results_summary.csv'}\")\n",
    "\n",
    "# Display detailed view of mismatches\n",
    "if 'gemini_partial' in globals() and gemini_partial:\n",
    "    print(\"\\\\n\" + \"=\"*100)\n",
    "    print(\"DETAILED INSPECTION: GEMINI PARTIAL MATCHES (syntax + exec pass, result mismatch)\")\n",
    "    print(\"=\"*100)\n",
    "    for i, record in enumerate(gemini_partial[:3], 1):\n",
    "        print(f\"\\\\n--- Mismatch #{i} ---\")\n",
    "        inspect_record(record)\n",
    "\n",
    "if 'qwen_partial' in globals() and qwen_partial:\n",
    "    print(\"\\\\n\\\\n\" + \"=\"*100)\n",
    "    print(\"DETAILED INSPECTION: QWEN PARTIAL MATCHES\")\n",
    "    print(\"=\"*100)\n",
    "    for i, record in enumerate(qwen_partial[:3], 1):\n",
    "        print(f\"\\\\n--- Mismatch #{i} ---\")\n",
    "        inspect_record(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Final Results\n",
    "\n",
    "results_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"test_set_size\": len(test_records),\n",
    "    \"models\": {\n",
    "        \"gemini_2.5_flash_lite\": {\n",
    "            \"metrics\": gemini_metrics,\n",
    "            \"full_results\": gemini_results,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Only include Qwen if results are available\n",
    "if 'qwen_metrics' in globals() and 'qwen_results' in globals():\n",
    "    results_summary[\"models\"][\"qwen3_4b_base\"] = {\n",
    "        \"metrics\": qwen_metrics,\n",
    "        \"full_results\": qwen_results,\n",
    "    }\n",
    "\n",
    "results_file = EVAL_DIR / \"evaluation_results.json\"\n",
    "with results_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\\\nFinal results saved to: {results_file}\")\n",
    "print(\"\\\\nEvaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Inspection Tool\n",
    "\n",
    "def inspect_by_id(record_id: str, results: list[dict[str, Any]] | None = None):\n",
    "    \"\"\"Inspect a specific record by ID from either gemini_results or qwen_results.\"\"\"\n",
    "    if results is None:\n",
    "        # Try both (only if they exist)\n",
    "        all_results = gemini_results.copy() if 'gemini_results' in globals() else []\n",
    "        if 'qwen_results' in globals():\n",
    "            all_results.extend(qwen_results)\n",
    "    else:\n",
    "        all_results = results\n",
    "    \n",
    "    for record in all_results:\n",
    "        if record.get(\"id\") == record_id:\n",
    "            inspect_record(record, max_rows_display=50)\n",
    "            return\n",
    "    print(f\"Record with ID '{record_id}' not found.\")\n",
    "\n",
    "# Example usage:\n",
    "# inspect_by_id(\"F5.2-000167-S1-P2\")  # Uncomment and run to inspect a specific record\n",
    "\n",
    "print(\"\\\\nUse inspect_by_id('RECORD_ID') to inspect a specific record in detail.\")\n",
    "print(\"Example: inspect_by_id('F5.2-000167-S1-P2')\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
