# OncoGraph Agent - Fine-Tuning Dataset Generation Plan

This document outlines the strategy and steps for generating a high-quality dataset for fine-tuning a bespoke Text-to-Cypher model. For the end-to-end model training and evaluation process, please refer to `FINETUNING_EXECUTION_PLAN.md`.

## 1. Overview & Goal

The current system uses a two-step LLM chain (Instruction Expansion → Cypher Generation) with a general-purpose model (Gemini). To improve latency, cost, and domain-specific accuracy, we are moving to a single, fine-tuned model that directly translates natural language questions into executable Cypher queries.

**Goal:** To systematically generate a high-quality dataset of `(question, cypher)` pairs that comprehensively covers the schemas, entities, and query patterns required by the OncoGraph agent.

## 2. Dataset Generation Strategy

We will create the dataset using a hybrid approach that combines systematic, template-based generation for broad coverage with data augmentation techniques to ensure linguistic diversity and robustness.

### Step 1: Systematic Generation via Templating
- **Method:** We will use Python-based template generators for a comprehensive set of query "families" (see below). These templates will be populated with real entity data (genes, diseases, variants, etc.) sampled from the project's CIViC data files.
- **Augmentation:** The generation script will leverage canonical entity names and their ingested synonyms (especially for diseases) to create a rich training set. For each core `(entity, cypher)` pair, the script will generate multiple varied questions using both the canonical name and its known aliases. Each question will be paired with a "gold" Cypher query generated by a deterministic, rule-based function.
- **Rationale:** This process teaches the model to map diverse user phrasing (e.g., "NSCLC" vs. "non-small cell lung cancer") to a single, robust, and correctly scoped query.
- **Output:** A large set of `(question, gold_cypher)` pairs. The Cypher is considered "gold" because it's generated from deterministic, correct templates, not an LLM.

### Step 2: Paraphrasing and Finalization
- **Method:** For each generated question, a set of pre-defined paraphrase templates will be applied to create additional linguistic variations.
- **Output:** A final, comprehensive set of pairs, which will then be sampled and split into `train_sample.jsonl` and `test_sample.jsonl` by a separate script as defined in the execution plan.

## 3. Query Families

To ensure comprehensive coverage of the graph's capabilities, the dataset is generated based on the following query patterns, structured from simple lookups to complex, multi-hop reasoning.

#### F1: Basic Entity Lookups (1-hop)
- **F1.1 (Therapy -> Gene):** Therapies targeting a specific `Gene`.
  - *Example:* "What drugs target BRAF?"
- **F1.2 (Gene -> Therapy):** Genes targeted by a specific `Therapy`.
  - *Example:* "Which genes does Dabrafenib target?"
- **F1.3 (Variant -> Gene):** The `Gene` a specific `Variant` belongs to.
  - *Example:* "Which gene is BRAF V600E a variant of?"
- **F1.4 (Gene -> Variants):** All `Variants` of a specific `Gene`.
  - *Example:* "List all known variants of the KRAS gene."

#### F2: Property-Based & Evidential Queries
- **F2.1 (TARGETS Properties):** Requesting properties from the `TARGETS` relationship.
  - *Example:* "What is Dabrafenib's mechanism of action on BRAF?"
- **F2.2 (AFFECTS_RESPONSE_TO Basic):** The effect of a `Biomarker` on a `Therapy`, often constrained by a `Disease`.
  - *Example:* "How does EGFR T790M affect response to Osimertinib in lung cancer?"
- **F2.3 (Evidential Properties):** Requesting specific evidence details from the `AFFECTS_RESPONSE_TO` relationship.
  - *Example:* "Provide PMIDs supporting that EGFR S492R confers resistance to cetuximab."
- **F2.4 (Node Properties):** Requesting properties from a node itself.
    - *Example:* "What is the consequence of the BRAF V600E variant?"

#### F3: Set-Based & Comparative Queries
- **F3.1 (Union):** Therapies targeting `Gene A` OR `Gene B`.
  - *Example:* "Find therapies for EGFR or ERBB2."
- **F3.2 (Intersection):** Therapies targeting `Gene A` AND `Gene B`.
  - *Example:* "What therapies target both BRAF and MEK1?"
- **F3.3 (Negative / Subtractive):** Therapies targeting `Gene A` but NOT `Gene B`.
  - *Example:* "Which drugs target KRAS but not NRAS?"

#### F4: Multi-Hop & Validation Queries (High Value)
- **F4.1 (Target Validation):** Find therapies that `TARGET` a specific `Gene` AND have known `AFFECTS_RESPONSE_TO` biomarker evidence in a `Disease`.
  - *Example:* "Which therapies target BRAF and also have biomarker evidence in melanoma?"
- **F4.2 (Alternative Therapy Discovery):** Find `Genes` that are resistance biomarkers for `Therapy A`, then find other therapies (`Therapy B`) that `TARGET` those `Genes`.
  - *Example:* "For therapies causing resistance via KRAS mutations, what are some alternative drugs targeting KRAS?"

#### F5: Disease-Centric & Discovery Queries
- **F5.1 (Disease -> Biomarkers):** Find all biomarkers (Genes or Variants) with evidence in a specific `Disease`.
  - *Example:* "In colorectal cancer, which ERBB2 or EGFR variants have biomarker evidence?"
- **F5.2 (Disease -> Therapies):** Find all therapies that have known biomarker evidence in a specific `Disease`.
  - *Example:* "List therapies with variant-level biomarkers in non-small cell lung cancer."

#### F6: Compositional Queries (High Value)
To ensure the model learns to handle complex, real-world questions, a dedicated family of compositional queries is included. These queries explicitly combine patterns from the simpler families to help the model generalize.

- **F6.1 (Evidence + Therapy Union + Disease Filter):** A combination of `F2.2`, `F3.1`, and `F5`.
  - *Example:* "Which genes predict resistance to cetuximab or panitumumab in colorectal cancer?"
- **F6.2 (Targeting + Negative Filter + Disease Evidence):** A combination of `F1.1`, `F3.3`, and `F4.1`.
  - *Example:* "What therapies target BRAF but NOT KRAS, and have biomarker evidence in melanoma?"
- **F6.3 (Targeting + Variant Evidence):** A combination of `F1.1`, `F2.2`, and `F5`.
  - *Example:* "Find therapies that target EGFR for variants that cause resistance in lung cancer."
- **F6.4 (Alternative Therapy via Resistance Genes + Disease):** A combination of `F4.2` and `F5`.
  - *Example:* "For resistance to cetuximab in colorectal cancer, which therapies target the resistance biomarkers?"

## 4. Key Generation Strategies

To ensure the model is robust, the dataset is designed to teach the following specific Cypher generation patterns.

### Disease Name Filtering: A Deterministic Approach

The system must handle both broad (e.g., "lung cancer") and specific (e.g., "lung adenocarcinoma") queries correctly. This intelligence is implemented as a simple, deterministic rule in the `generate_dataset.py` script, not inferred by the LLM.

- **The LLM's Task:** The fine-tuned model's only job is to learn to map a user's phrasing to the most appropriate canonical disease name from the database. It is a simple "translation" task, trained using the disease names and their ingested synonyms.
- **The Dataset Generator's Logic (The "Cancer" Rule):** The script that generates the "gold" Cypher query applies the following rule:
  > When tokenizing a canonical disease name, if the word `"cancer"` is present **and** it is not the only word, remove it from the list of tokens used to build the query.
- **Behavior:** This single rule produces the desired high-recall/high-precision behavior:
  - `"Lung Cancer"` (tokens `{'lung', 'cancer'}`) → rule applies → query uses `['lung']` → **High-Recall Search**.
  - `"Lung Carcinoma"` (tokens `{'lung', 'carcinoma'}`) → rule does not apply → query uses `['lung', 'carcinoma']` → **High-Precision Search**.
  - `"Cancer"` (token `{'cancer'}`) → rule does not apply → query uses `['cancer']` → **High-Precision Search**.

- **Example High-Recall Gold Cypher (for "Lung Cancer"):**
  ```cypher
  ...
  WHERE toLower(rel.disease_name) CONTAINS toLower('lung')
  ...
  ```

- **Example High-Precision Gold Cypher (for "Lung Carcinoma"):**
  ```cypher
  ...
  WHERE toLower(rel.disease_name) CONTAINS toLower('lung')
    AND toLower(rel.disease_name) CONTAINS toLower('carcinoma')
  ...
  ```

This deterministic approach ensures that the logic is simple, testable, and robust, giving the LLM a clean and achievable learning task.

### Canonical Rule Coverage (Alignment with prompts.py)

The dataset must explicitly teach every canonical behavior encoded in `src/pipeline/prompts.py`. These rules ensure the fine-tuned model generates Cypher queries that match the behavior of the existing system.

#### Rules to Teach (Non-Exhaustive but Mandatory)

- **Gene-only AFFECTS:** Collapse evidence to gene level; set `variant_name = NULL`; de-duplicate by `(gene_symbol, therapy_name, disease_name)`; aggregate `pmids` across rows; return `pmids` as array (default `[]`).
- **Variant-specific AFFECTS:** Prefer equality on full variant name; if only a token (e.g., `G12C`), use guarded fallbacks: `Variant.name CONTAINS`, or `hgvs_p = 'p.<TOKEN>'`, or `synonyms CONTAINS`; always guard with `[:VARIANT_OF]` to the gene.
- **Fusions:** Match both orientations (e.g., `EML4::ALK` and `ALK::EML4`).
- **Alteration Classes:** Handle tokens like `Amplification`, `Overexpression`, `Deletion`, `Loss-of-function`, `Fusion`, `Wildtype` with `VARIANT_OF` guard.
- **TARGETS:** Project `r.moa AS targets_moa`; derive `pmids` from `r.ref_sources/r.ref_ids` where source contains `pubmed` or equals `pmid` (case-insensitive); also return `ref_sources/ref_ids/ref_urls`.
- **Therapy Resolution:** Match by exact name; synonyms equality; `toLower(t.name) CONTAINS`; therapy class via `tags` or via explicit `[:TARGETS]` to the gene.
- **Disease Filters:** Umbrella terms use minimal anchor token(s); specific diseases use canonical tokens; apply the "Cancer Rule" from this plan; disease aliases expand question phrasing in training, not schema.
- **Filter Scoping:** Attach WHERE filters to the bindings they constrain; do not place relationship filters under `OPTIONAL MATCH`.
- **Arrays:** Wrap with `coalesce(..., [])` before `any()/all()`; always return `pmids` as an array (default `[]`).
- **Effects:** Compare case-insensitively (`toLower(rel.effect) = 'resistance'|'sensitivity'`).
- **Returns:** Include `therapy_name` and at least one of `variant_name` or `gene_symbol`; use minimal sufficient columns; set missing columns to `NULL`; include `LIMIT`; no parameters (no `$vars`).

#### Family Coverage Map

Each query family explicitly teaches specific rule patterns:

- **F1.1/F1.2:** TARGETS lookups; therapy name/synonyms; tags-based class; minimal returns.
- **F1.3/F1.4:** VARIANT_OF guard; variant/gene traversal; alteration class tokens.
- **F2.1:** MOA + reference-derived pmids; include reference arrays.
- **F2.2:** AFFECTS gene-only and variant-specific; sensitivity/resistance; disease filters; pmids as array.
- **F2.3:** Evidence property extraction (e.g., PMIDs).
- **F2.4:** Node properties (e.g., variant `consequence`).
- **F3:** Union/intersection/negative on genes/therapies.
- **F4.1:** Target validation combining TARGETS + AFFECTS + disease; correct filter scoping; mixed return schema.
- **F4.2:** Alternative therapy via resistance genes; multi-hop with disease.
- **F5:** Disease name handling with aliases and the deterministic Cancer Rule.
- **F6:** Compositional combinations of the above (generalization exemplars).

#### Dataset Generation Requirements (Must Include Explicit Examples For)

The dataset generation must include explicit examples demonstrating:

- Gene-only AFFECTS with pmid aggregation and de-duplication.
- Variant-specific AFFECTS: full names, bare tokens (e.g., `G12C`), `hgvs_p`, synonyms.
- Fusion variants both orientations.
- Alteration-class tokens with `VARIANT_OF` guard.
- TARGETS with reference-derived pmids and returned reference arrays.
- Therapy class via `tags` (e.g., "anti-EGFR") and fallback via TARGETS.
- Disease broad vs specific for the same evidence (e.g., "Lung Cancer" vs "Lung Carcinoma" vs NSCLC) per Cancer Rule.
- Set ops: union, intersection, negative (e.g., "KRAS but not NRAS").
- Mixed return schemas with NULL placeholders where fields are inapplicable.
- Usage of `coalesce(..., [])` in `any()/all()` over arrays; inclusion of `LIMIT`; no parameters.

See the `FINETUNING_DECISION_LOG.md` for a more detailed history of how these generation strategies were developed and refined.
